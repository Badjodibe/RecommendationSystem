{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac014159-ba92-4521-97f7-273489626947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "from operator import itemgetter\n",
    "from math import sqrt\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016f5d3d-789f-4c97-8182-91d665d1eed8",
   "metadata": {},
   "source": [
    "<h3 style = \"color:blue\"> Analyse Exploratoir </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d1957-62a3-43e9-b2c6-9b5c1ca2f99d",
   "metadata": {},
   "source": [
    "<p> \n",
    "    Les données que nous allons utliser dans ce etude provienne du site web GroupLens de l'univerisite de Minnesota, <a href=\"https://grouplens.org/datasets/movielens/\"> que vous pouvez vister pour plus d'information</a>. Dans ce étude on a utilisé le dataset ml-100k.zip, juste a coté il y a le README qui donne plus d'information sur la donnée. Liser le pour comprendre le fichier. Les deux fichier qui nous interesse dans ce cas sont: <span style=\"color:red\"> u.data </span> qui contient score des utilisation sur les film et <span style=\"color:red\"> u.item </span> contenant les informations sur les films.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f645a-e642-47f8-a7d2-9fdc2d9f13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.fromtimestamp(388474259))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9233875-4a87-48ef-9f28-046b98cc959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(path, **kwargs):\n",
    "    \"\"\" \n",
    "    On va charger les information des utilisation sur le films\n",
    "    \"\"\"\n",
    "    # Redefinition des options\n",
    "    options = {'fieldnames':('userid', 'movieid', 'rating', 'timestamp'),'delimiter':'\\t'}\n",
    "    options.update(kwargs)\n",
    "    # changement de la representation du temps de timestamp a datetime\n",
    "    parse_date = lambda r,k: datetime.fromtimestamp(float(r[k])) # convertion de timestamp\n",
    "    # convertion des entier de string a int\n",
    "    parse_int = lambda r,k: int(r[k])\n",
    "    # lecture notre donnees sous forme de dictionnaire\n",
    "    with open(path, 'r') as reviews:\n",
    "        reader = csv.DictReader(reviews, **options)\n",
    "        for row in reader:\n",
    "            row['userid'] = parse_int(row, 'userid')\n",
    "            row['movieid'] = parse_int(row, 'movieid')\n",
    "            row['rating'] = parse_int(row, 'rating')\n",
    "            row['timestamp'] = parse_date(row,'timestamp')\n",
    "            yield row\n",
    "    \n",
    "def relative_path(path):\n",
    "    \"\"\"\n",
    "    Cette fonction nous permettra d'avoir absolue du fichier de ce code. ainsi on\n",
    "    va l'utiliser pour charger notre donne\n",
    "    \"\"\"\n",
    "    direname = os.path.dirname(os.path.realpath('__file__'))\n",
    "    direname = '/'.join(direname.split('/')[:-1])\n",
    "    path = os.path.join(direname, path)\n",
    "    return os.path.normpath(path)\n",
    "\n",
    "def load_movied(path, **kwargs):\n",
    "    \"\"\"\n",
    "    Loads MovieLens movies\n",
    "    \"\"\"\n",
    "    options = {\n",
    "            'fieldnames': ('movieid', 'title', 'release',\n",
    "                        'video', 'url'),'delimiter': '|','restkey': 'genre',\n",
    "            \n",
    "    }\n",
    "    \n",
    "    options.update(kwargs)\n",
    "    parse_int = lambda r,k: int(r[k])\n",
    "    parse_date = lambda r,k: datetime.strptime(r[k], '%d-%b-%Y') if r[k] else None\n",
    "    \n",
    "    with open(path, 'r', encoding='latin-1') as movies:\n",
    "        reader = csv.DictReader(movies, **options)\n",
    "        for row in reader:\n",
    "            row['movieid'] = parse_int(row, 'movieid')\n",
    "            row['release'] = parse_date(row, 'release')\n",
    "            row['video']   = parse_date(row, 'video')\n",
    "            yield row\n",
    "            \n",
    "class MovieLens(object):\n",
    "    \"\"\"\n",
    "    Structure de données pour construre notre systeme de recommandation\n",
    "    \"\"\"\n",
    "    def __init__(self, udata, uitem):\n",
    "        self.udata = udata\n",
    "        self.uitem = uitem\n",
    "        self.movies ={}\n",
    "        self.reviews = defaultdict(dict)\n",
    "        self.load_dataset()\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        \"\"\"\n",
    "        Chargement de données en memoire\n",
    "        \"\"\"\n",
    "        for movie in load_movied(self.uitem):\n",
    "            self.movies[movie['movieid']] = movie\n",
    "        for review in load_reviews(self.udata):\n",
    "            self.reviews[review['userid']][review['movieid']] = review\n",
    "            \n",
    "    def reviews_for_movie(self, movieid):\n",
    "        for review in self.reviews.values():\n",
    "            if movieid in review:\n",
    "                yield review[movieid]\n",
    "                \n",
    "    def average_reviews(self):\n",
    "        for movieid in self.movies:\n",
    "            reviews = list(r[\"rating\"] for r in self.reviews_for_movie(movieid))\n",
    "            average = sum(reviews)/float(len(reviews))\n",
    "            yield (movieid, average, len(reviews)) \n",
    "            \n",
    "    def top_rated(self, n=10):\n",
    "        \"\"\"\n",
    "        renvoi les 10 premier film qui ont un score elevé\n",
    "        \"\"\"\n",
    "       # return heapq.nlargest(n, self.average_reviews(), key = itemgetter(1))\n",
    "        return heapq.nlargest(n, self.bayesian_average(), key = itemgetter(1))\n",
    "    \n",
    "    def bayesian_average(self, c=59, m=3):\n",
    "        for movieid in self.movies:\n",
    "            reviews = list(r[\"rating\"] for r in self.reviews_for_movie(movieid))\n",
    "            average = (c*m + sum(reviews))/float(c+len(reviews))\n",
    "            yield (movieid, average, len(reviews)) \n",
    "            \n",
    "    def shared_preference(self, criticsA, criticsB):\n",
    "        \n",
    "        if criticsA not in self.reviews:\n",
    "            raise KeyError(\"Couldn't find critics {} in data\".format(criticsA))\n",
    "        if criticsB not in self.reviews:\n",
    "            raise KeyError(\"Couldn't find critics {} in data\".format(criticsB))\n",
    "        \n",
    "        moviesA = set(self.reviews[criticsA].keys())\n",
    "        moviesB = set(self.reviews[criticsB].keys())\n",
    "        shared  = moviesA & moviesB\n",
    "        \n",
    "        reviews = {}\n",
    "        for movieid in shared:\n",
    "            reviews[movieid] = (\n",
    "                self.reviews[criticsA][movieid]['rating'],\n",
    "                self.reviews[criticsB][movieid]['rating']\n",
    "            )\n",
    "        return reviews\n",
    "                \n",
    "    def euclidean_distance(self, criticsA, criticsB):\n",
    "                preferences = self.shared_preference(criticsA, criticsB)\n",
    "                if len(preferences) == 0 : return 0\n",
    "                sum_of_squares = sum([pow(a-b,2) for a,b in preferences.values()])\n",
    "                return 1/(1+sqrt(sum_of_squares))\n",
    "    def pearson_correlation(self, criticsA, criticsB, prefs = \"user\"):\n",
    "        \n",
    "        preference = {\n",
    "            \"user\":self.shared_preference,\n",
    "            \"movies\": self.shared_critics\n",
    "        }\n",
    "        shared_ = preference.get(prefs, None)\n",
    "        preferences = shared_(criticsA, criticsB)\n",
    "        \n",
    "        lenght = len(preferences)\n",
    "        if lenght == 0 : return 0\n",
    "        \n",
    "        sumA = sumB = sumSquaresA = sumSquaresB = sumProducts = 0\n",
    "        \n",
    "        for a, b in preferences.values():\n",
    "            sumA+=a\n",
    "            sumB+=b\n",
    "            sumSquaresA+= pow(a, 2)\n",
    "            sumSquaresB+= pow(b, 2)\n",
    "            sumProducts+= a*b\n",
    "            \n",
    "        numerator = (sumProducts*lenght) - (sumA*sumB)\n",
    "        denominator = sqrt(((sumSquaresA*lenght) - pow(sumA, 2))* ((sumSquaresB*lenght) - pow(sumB, 2)))\n",
    "        \n",
    "        if denominator == 0 : return 0\n",
    "        return abs(numerator/denominator)\n",
    "    \n",
    "    def similar_critics(self, user, metric = 'euclidean' , n = None):\n",
    "        \n",
    "        metrics = {\n",
    "            'euclidean': self.euclidean_distance,\n",
    "            'pearson' : self.pearson_correlation\n",
    "        }\n",
    "        \n",
    "        distance = metrics.get(metric, None)\n",
    "        \n",
    "        if user not in self.reviews:\n",
    "            raise KeyError(\"Unknown user, {}\".format(user))\n",
    "        if not distance or not  callable(distance):\n",
    "            raise KeyError(\"Unknown or unprogrammed distance metric {}\".format(metric))\n",
    "            \n",
    "        critics = {}\n",
    "        for critic in self.reviews:\n",
    "            if critic == user:\n",
    "                continue\n",
    "            critics[critic] = distance(user, critic)\n",
    "        \n",
    "        if n:\n",
    "            return heapq.nlargest(n, critics.items(), key = itemgetter(1))\n",
    "        \n",
    "        return critics\n",
    "    \n",
    "    def predict_raking(self, user, movie, metric = \"euclidean\",  critics = None):\n",
    "        \n",
    "        critics = critics or self.similar_critics(user, metric = metric)\n",
    "        total = 0\n",
    "        simsum = 0\n",
    "        \n",
    "        for critic, similarity in critics.items():\n",
    "            if movie in self.reviews[critic]:\n",
    "                total+= similarity * self.reviews[critic][movie]['rating']\n",
    "                simsum+=similarity\n",
    "        if simsum == 0.0: return 0.0\n",
    "        return total/simsum\n",
    "    \n",
    "    def predict_all_rankings(self, user, metric = \"euclidean\", n = None):\n",
    "        \n",
    "        critics = self.similar_critics(user, metric = metric)\n",
    "        movies = {\n",
    "            movie : self.predict_rating(user, movie, metric, critics) for movie in self.movies\n",
    "        }\n",
    "        \n",
    "        if n:\n",
    "            return heapq.nlargest(n, movies.items(), key = itemgetter(1))\n",
    "        return movies\n",
    "    def shared_critics(self, movieA, movieB):\n",
    "        \n",
    "        if movieA not in self.movies:\n",
    "            raise KeyError(\"could not find {} in data\".format(movieA))\n",
    "        if movieB not in self.movies:\n",
    "            raise KeyError(\"could not find {} in data\".format(movieB))\n",
    "            \n",
    "        criticsA = set(critic for critic in self.reviews if movieA in self.reviews[critic])\n",
    "        criticsB = set(critic for critic in self.reviews if movieB in self.reviews[critic])\n",
    "        \n",
    "        shared = criticsA&criticsB\n",
    "        \n",
    "        reviews = {}\n",
    "        for critic in shared :\n",
    "            reviews[critic] = (\n",
    "                self.reviews[critic][movieA][\"rating\"],\n",
    "                self.reviews[critic][movieB][\"rating\"]\n",
    "            )\n",
    "        return reviews\n",
    "    \n",
    "    def similar_items(self, movie, metric = \"euclidean\", n=None):\n",
    "        \n",
    "        metrics = {\n",
    "            'euclidean': self.euclidean_distance,\n",
    "            'pearson': self.pearson_correlation\n",
    "        }\n",
    "        \n",
    "        distance = metrics.get(metric, None)\n",
    "        \n",
    "        if movie not in self.reviews:\n",
    "            raise KeyError(\"Unknown movie {}\".format(movie))\n",
    "        if not distance or not callable(distance):\n",
    "            raise KeyError(\"Unknow or not programmed distance {}\".format(distance))\n",
    "            \n",
    "        items = {}\n",
    "        for item in self.movies:\n",
    "            if item == movie:\n",
    "                continue\n",
    "            items[item] = distance(item, movie, prefs = 'movies')\n",
    "        if n:\n",
    "            return heapq.nlargest(n, items.items, key = itemgetter(1))\n",
    "        return items\n",
    "    \n",
    "    def predict_ranking_(self, user, movie, metric = \"euclidean\"):\n",
    "        movies = self.similar_items(movie, metric=metric)\n",
    "        total = 0\n",
    "        simsum = 0\n",
    "        \n",
    "        for relmovie, similarity in movies.items():\n",
    "            if relmovie in self.reviews[user]:\n",
    "                total+= similarity*self.reviews[user][relmovie]['rating']\n",
    "                simsum+=similarity\n",
    "        if simsum == 0.0 : return 0.0\n",
    "        return total/simsum\n",
    "        \n",
    "        \n",
    "class Recommender(object):\n",
    "    \n",
    "    @classmethod\n",
    "    def load(k_class, pickle_path):\n",
    "        \n",
    "        with open(pickle_path, 'rb') as pkl:\n",
    "            return pickle.load(pkl)\n",
    "    \n",
    "    def __init__(self, udata, description = None):\n",
    "        self.udata = udata\n",
    "        self.users = None\n",
    "        self.reviews = None\n",
    "        self.movies = None\n",
    "        \n",
    "        self.build_start = None\n",
    "        self.build_finish = None\n",
    "        self.description = None\n",
    "        \n",
    "        self.model = None\n",
    "        self.features = 2\n",
    "        self.steps = 5000\n",
    "        self.alpha = 0.0002\n",
    "        self.beta = 0.02\n",
    "        \n",
    "        self.load_dataset()\n",
    "\n",
    "    def dump(self, pickle_path):\n",
    "        \n",
    "        with open( pickle_path, 'rb') as pkl:\n",
    "            pickle.dump(self, pkl)\n",
    "    def load_dataset(self):\n",
    "            \n",
    "            self.users = set([])\n",
    "            self.movies = set([])\n",
    "        \n",
    "            for review in load_reviews(self.udata):\n",
    "            \n",
    "                self.users.add(review['userid'])\n",
    "                self.movies.add(review['movieid'])\n",
    "            \n",
    "            self.users = sorted(self.users)\n",
    "            self.movies = sorted(self.movies)\n",
    "            self.reviews = np.zeros(shape = (len(self.users), len(self.movies)))\n",
    "        \n",
    "            for review in load_reviews(self.udata):\n",
    "                uid = self.users.index(review['userid'])\n",
    "                mid = self.movies.index(review['movieid'])\n",
    "                self.reviews[uid, mid] = review['rating']\n",
    "            \n",
    "    def sparsity(self):\n",
    "                \n",
    "        return 1 - self.density()\n",
    "            \n",
    "    def density(self):\n",
    "                \n",
    "        nonzero = float(np.count_nonzero(self.reviews))\n",
    "        return nonzero/self.reviews.size\n",
    "    \n",
    "    def build(self, output = None):\n",
    "        \n",
    "        options = {\n",
    "            'K':self.features,\n",
    "            'steps':self.steps,\n",
    "            'alpha':self.alpha,\n",
    "            'beta':self.beta\n",
    "        }\n",
    "        \n",
    "        self.build_start = time.time()\n",
    "        self.P, self.Q = factor(self.reviews, **options)\n",
    "        self.mfModel = np.dot(self.P, self.Q.T)\n",
    "        self.build_finish = time.time()\n",
    "        \n",
    "        if output:\n",
    "            self.dump(output) \n",
    "    def predict_ranking(self, user, movie):\n",
    "        \n",
    "        uidx  =  self.users.index(user)\n",
    "        midx  = self.movies.index(movie)\n",
    "        \n",
    "        if self.reviews[uidx, midx] > 0:\n",
    "            return None\n",
    "        return self.model[uidx, midx]\n",
    "        \n",
    "    def top_rated(self, user, n = 12):\n",
    "        \n",
    "        movies = [(mid, self.predict_ranking(user, mid)) for mid in self.movies ]\n",
    "    \n",
    "\n",
    "def initialize(R, K):\n",
    "    \n",
    "    N, M = R.shape\n",
    "    P   = np.random.rand(N, K)\n",
    "    Q   = np.random.rand(M, K)\n",
    "    \n",
    "    return P, Q\n",
    "\n",
    "def factor(R, P=None, Q=None, K = 2, steps = 5000, alpha = 0.0002, beta = 0.02):\n",
    "    \n",
    "    \n",
    "    if not P and not Q :\n",
    "        P, Q = initialize(R, K)\n",
    "    \n",
    "    Q = Q.T\n",
    "    \n",
    "    rows, cols = R.shape\n",
    "    for step in range(steps):\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                if R[i,j] > 0:\n",
    "                    eij = R[i,j] - np.dot(P[i, :], Q[:,j])\n",
    "                    for k in range(K):\n",
    "                        P[i,k] = P[i,k] + alpha * (2*eij*Q[k,j] - beta*P[i,k])\n",
    "                        Q[k,j] = Q[k,j] + alpha * (2*eij*P[i,k] - beta*Q[k,j])\n",
    "        e = 0\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                 if R[i,j] > 0:\n",
    "                    e = e + pow(R[i,j] - np.dot(P[i,:], Q[:,j]),2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * (pow(P[i,k], 2) + pow(Q[k, j], 2))\n",
    "        if e < 0.001:\n",
    "                break\n",
    "    return P, Q.T\n",
    "    \n",
    "data  = relative_path('Data/ml-100k/u.data')\n",
    "item  = relative_path('Data/ml-100k/u.item')\n",
    "model = MovieLens(data, item)\n",
    "mfModel = Recommender(data)         \n",
    "mfModel.build('reccord.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21af969-b305-4e15-a140-55807fe43aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64618968-1cae-482d-ad8f-23079a2eae4c",
   "metadata": {},
   "source": [
    "<h3 style = \"color:blue\"> Recherche le filme qui a plus de score </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818c8e7-cb14-457f-aff1-ed4c004d972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for mid, avg, num in model.top_rated(20):\n",
    "    #title =model.movies[mid][\"title\"]\n",
    "    #print(\"[%0.3f averagae rating (%i reviews)] %s\" %( avg, num, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6fb3d-a495-4269-9812-49f7e6891ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mid, avg, num in model.top_rated(20):\n",
    "    #title =model.movies[mid][\"title\"]\n",
    "    #print(\"[%0.3f averagae rating (%i reviews)] %s\" %( avg, num, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef6cca-bf94-44b1-93ec-12daa0dec02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.euclidean_distance(532, 232))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcad9b2-d578-41ab-9ada-d22062799807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.pearson_correlation(532, 232))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62952455-77b0-4537-834b-fdf8438096f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in model.similar_critics(232, metric=\"euclidean\", n = 10):\n",
    "    #print ( \"%4i: %0.3f\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d753316-9bf9-4a31-84ba-1fe377346539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in model.similar_critics(232, metric=\"pearson\", n = 10):\n",
    "    #print ( \"%4i: %0.3f\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e12e53-c59f-4bfa-8a53-8e6cef6abadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( model.predict_rating(422, 50 , metric = \"euclidean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ac3cf-19d6-4161-b96c-c549fa0c4041",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( model.predict_rating(422, 50, metric = \"pearson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf1a74-b4f9-4253-b708-7eabec8c2f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mid, rating in model.predict_all_rankings(578, 'pearson', 10) :\n",
    "    #print(\"%0.3f  %s\" %(rating, model.movies[mid]['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ce333-bc3a-4e9c-9cca-d118a5f064f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.shared_preference(232, 532)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3e59a-5c96-499d-a1bb-437bbbc64d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for movie, simillarity in model.similar_items(631, 'pearson').items():\n",
    "    #print(\"%0.3f :%s\" % (simillarity, model.movies[movie][\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1275839c-adc6-406a-8445-1df875179cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict_ranking_(232, 52, 'pearson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f23fc2-6928-4033-84c2-e24500e387c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} spare\".format(mfModel.sparsity()))\n",
    "print(\"%0.3f dense\" % mfModel.density())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bab2aa-2a76-4f32-9334-0dcbad2a197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = Recommender.load('reccorr.pickle')\n",
    "for item in rec.top_rated(234):\n",
    "    print(\"%i: %0.3f\" %item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f115fd-354e-4257-bab3-4ef21b2d3649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11edc493-df50-460e-bbe5-9e038f0dd0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
